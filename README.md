# Localight for iOS
[![License: MIT](https://img.shields.io/badge/license-MIT-orange)](https://opensource.org/license/mit)
![Framework](https://img.shields.io/badge/SwiftUI-orange)
![Platform](https://img.shields.io/badge/Platforms-iOS-orange)
![Apple](https://img.shields.io/badge/Apple-000000?style=flat&logo=apple)

**Localight** is a simple SwiftUI chatbot app for iOS 26, powered entirely by Apple‚Äôs on-device Foundation Models. Designed for demonstration purposes, Localight offers fast, private, and completely offline AI chat ‚Äî no internet connection or server required.

Localight showcases how to integrate Apple's local LLM into a native iOS experience using SwiftUI and the new [Foundation Models](https://developer.apple.com/documentation/foundationmodels) framework.

‚ö†Ô∏è **Disclaimer**: This app is for demonstration purposes only and is not production-ready. Output generated by the local large language model may be inaccurate, incomplete, or misleading.

## ‚ú® Features

- üß† **On-device LLM**: Uses Apple‚Äôs local Foundation Models for text generation.
- üîê **Privacy-first**: All conversations stay on your device. No data is sent to the cloud.
- ‚ö° **Fast & Offline**: No internet needed. Responses are generated locally.
- üí¨ **Minimalist Chat UI**: Clean SwiftUI interface for interacting with the model.
- üóëÔ∏è **No history**: Conversation is not saved after closing the app.

## üõ† Manual
- **Import the Library**: To work with [Foundation Models](https://developer.apple.com/documentation/foundationmodels), you must import the library in every file where you intend to use them. Go with:
    ```swift
    import FoundationModels
    ```

- **Check Availability**: The key object is the [SystemLanguageModel](https://developer.apple.com/documentation/foundationmodels/systemlanguagemodel). This can indicate whether the model is ```.available``` or ```.unavailable```. In case of unavailability, a reason is also provided.

- **Create a LanguageModelSession**: To start prompting, you need to create a [LanguageModelSession](https://developer.apple.com/documentation/foundationmodels/languagemodelsession). When you create a session you can provide instructions that tells the model what its role is and provides guidance on how to respond. These instructions should never be editable by the user:
    ```swift
    let session = LanguageModelSession(instructions: "You are the best friend.")
    ```

- **Generate a Response**: Finally, call the method to receive a result as a String by using: 
    ```swift
    let response = try await session.respond(to: promptAsString).content
    ```

- **Stream a Response**: Otherwise, you can call the method to receive a result as a String that is streamed by using: 
    ```swift
    let stream = session.streamResponse(to: promptAsString)

    do {
        for try await chunk in stream {
            self.streamingResponse = chunk.content
        }
        
        let response = try await stream.collect().content
    } catch {}
    ```

## üìè Context Window & Token Limits
Apple‚Äôs on-device Foundation Models operate with a limited context window per session. 
The context window defines how many tokens the model can process within a single ```LanguageModelSession```.
- A token is a unit of text processed by the model.
- In Western languages (e.g. English or German), 1 token ‚âà 3‚Äì4 characters.
- In East Asian languages (e.g. Japanese or Chinese), 1 token ‚âà 1 character.
- The system model currently supports up to **4,096 tokens** per session.

If this limit is exceeded, the framework throws the following error: ```LanguageModelSession.GenerationError.exceededContextWindowSize(_:)```

For more details, see Apple‚Äôs official documentation:
[TN3193 ‚Äì Managing the on-device foundation model‚Äôs context window](https://developer.apple.com/documentation/technotes/tn3193-managing-the-on-device-foundation-model-s-context-window)
